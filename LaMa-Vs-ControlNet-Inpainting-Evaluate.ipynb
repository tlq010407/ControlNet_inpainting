{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95569263-6800-457a-97cc-1f4e65dccc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/liqi/anaconda3/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/liqi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/liqi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/liqi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/liqi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/liqi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/liqi/anaconda3/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3bba339-f63e-4eb2-bae9-df3396cd0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from diffusers import ControlNetModel, StableDiffusionInpaintPipeline\n",
    "from skimage.metrics import peak_signal_noise_ratio as compute_psnr\n",
    "from skimage.metrics import structural_similarity as compute_ssim\n",
    "import lpips  # pip install lpips\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import cv2  # OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Set seeds for reproducibility\n",
    "# ---------------------------\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5961594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Utility: Mask refinement using morphological closing\n",
    "# ---------------------------\n",
    "def refine_mask_cv(mask, kernel_size=3, iterations=1):\n",
    "    \"\"\"\n",
    "    Refine a binary mask using morphological closing to smooth out noise.\n",
    "    Adjust kernel_size and iterations for your data.\n",
    "    \"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    refined_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
    "    return refined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46308a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Inpainting functions\n",
    "# ---------------------------\n",
    "def run_lama_inpaint(image_path, mask_path, output_path):\n",
    "    from simple_lama_inpainting import SimpleLama  # import here in case it's not global\n",
    "    simple_lama = SimpleLama()\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    result = simple_lama(image, mask)\n",
    "    result.save(output_path)\n",
    "    \n",
    "def run_opencv_inpaint(image_path, mask_path, output_path, inpaintRadius=3, method=cv2.INPAINT_TELEA, refine=True):\n",
    "    \"\"\"\n",
    "    OpenCV inpainting using the Telea algorithm.\n",
    "    Reads the image and mask using OpenCV, thresholds the mask to ensure it's binary,\n",
    "    optionally refines the mask, performs inpainting, and saves the result.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Ensure mask is binary\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    if refine:\n",
    "        mask = refine_mask_cv(mask, kernel_size=3, iterations=1)\n",
    "    inpainted = cv2.inpaint(image, mask, inpaintRadius, method)\n",
    "    cv2.imwrite(output_path, inpainted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# ControlNet helper functions\n",
    "# ---------------------------\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "def clean_huggingface_cache(model_path):\n",
    "    \"\"\"Remove unnecessary Hugging Face cache directories and .lock files.\"\"\"\n",
    "    for root, dirs, files in os.walk(model_path, topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(\".lock\"):\n",
    "                os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            if name.startswith(\"models--\") or name == \"temp\":\n",
    "                shutil.rmtree(os.path.join(root, name), ignore_errors=True)\n",
    "\n",
    "def get_latest_snapshot(model_path):\n",
    "    \"\"\"Find and move the correct snapshot folder for a downloaded model.\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        for subdir in os.listdir(model_path):\n",
    "            snapshot_path = os.path.join(model_path, subdir, \"snapshots\")\n",
    "            if os.path.exists(snapshot_path):\n",
    "                snapshots = sorted(os.listdir(snapshot_path), reverse=True)\n",
    "                if snapshots:\n",
    "                    latest_snapshot = os.path.join(snapshot_path, snapshots[0])\n",
    "                    for file_name in os.listdir(latest_snapshot):\n",
    "                        src = os.path.join(latest_snapshot, file_name)\n",
    "                        dest = os.path.join(model_path, file_name)\n",
    "                        if not os.path.exists(dest):\n",
    "                            shutil.move(src, dest)\n",
    "                    shutil.rmtree(os.path.dirname(latest_snapshot), ignore_errors=True)\n",
    "                    return model_path\n",
    "    return model_path\n",
    "\n",
    "def check_and_download_model(model_name, model_path, is_controlnet=False):\n",
    "    \"\"\"Check if the model exists; if not, download and move it to the correct directory.\"\"\"\n",
    "    if is_controlnet:\n",
    "        model_path = os.path.join(model_path, \"controlnet\")\n",
    "    else:\n",
    "        model_path = os.path.join(model_path, \"stable-diffusion\")\n",
    "\n",
    "    if os.path.exists(model_path) and os.listdir(model_path):\n",
    "        return\n",
    "\n",
    "    # Download silently\n",
    "    temp_dir = os.path.join(\"models\", \"temp\")\n",
    "    if is_controlnet:\n",
    "        ControlNetModel.from_pretrained(model_name, cache_dir=temp_dir)\n",
    "    else:\n",
    "        StableDiffusionInpaintPipeline.from_pretrained(model_name, cache_dir=temp_dir)\n",
    "\n",
    "    correct_model_path = get_latest_snapshot(temp_dir)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    for file_name in os.listdir(correct_model_path):\n",
    "        src = os.path.join(correct_model_path, file_name)\n",
    "        dest = os.path.join(model_path, file_name)\n",
    "        if not os.path.exists(dest):\n",
    "            shutil.move(src, dest)\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "def load_controlnet():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    models_dir = \"models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    controlnet_dir = os.path.join(models_dir, \"controlnet\")\n",
    "    stable_diffusion_dir = os.path.join(models_dir, \"stable-diffusion\")\n",
    "    os.makedirs(controlnet_dir, exist_ok=True)\n",
    "    os.makedirs(stable_diffusion_dir, exist_ok=True)\n",
    "\n",
    "    check_and_download_model(\"stabilityai/stable-diffusion-2-inpainting\", models_dir, is_controlnet=False)\n",
    "    check_and_download_model(\"lllyasviel/control_v11p_sd15_inpaint\", models_dir, is_controlnet=True)\n",
    "\n",
    "    clean_huggingface_cache(models_dir)\n",
    "\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        stable_diffusion_dir, torch_dtype=torch_dtype, local_files_only=True\n",
    "    ).to(device, dtype=torch_dtype)\n",
    "    return pipe\n",
    "\n",
    "def make_divisible_by_8(size):\n",
    "    \"\"\"Ensure both width and height are divisible by 8.\"\"\"\n",
    "    width, height = size\n",
    "    width = (width // 8) * 8\n",
    "    height = (height // 8) * 8\n",
    "    return width, height\n",
    "\n",
    "def run_controlnet_inpaint(image_path, mask_path, pipe, reference_images, prompt, output_path, seed=42):\n",
    "    # Open image and mask\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    original_size = image.size\n",
    "    adjusted_size = make_divisible_by_8(original_size)\n",
    "\n",
    "    conditioning = None\n",
    "    if reference_images:\n",
    "        conditioning = [\n",
    "            img.resize(adjusted_size, Image.Resampling.LANCZOS)\n",
    "            for img in reference_images\n",
    "        ]\n",
    "\n",
    "    # Create a generator with a fixed seed for reproducibility\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        image=image.resize(adjusted_size, Image.Resampling.LANCZOS),\n",
    "        mask_image=mask.resize(adjusted_size, Image.Resampling.LANCZOS),\n",
    "        conditioning_image=conditioning,\n",
    "        height=adjusted_size[1],\n",
    "        width=adjusted_size[0],\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "    result = result.resize(original_size, Image.Resampling.LANCZOS)\n",
    "    result.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb287a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# LPIPS model loading\n",
    "# ---------------------------\n",
    "def load_lpips_model(model_dir=\"models/lpips\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, \"lpips_alex.pth\")\n",
    "    model = lpips.LPIPS(net='alex')\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model\n",
    "\n",
    "lpips_model = load_lpips_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbad417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Evaluation functions\n",
    "# ---------------------------\n",
    "def prepare_for_lpips(pil_image):\n",
    "    tensor = transforms.ToTensor()(pil_image).unsqueeze(0)\n",
    "    tensor = tensor * 2 - 1\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def evaluate_metrics(gt_img, inpaint_img):\n",
    "    gt_np = np.array(gt_img).astype(np.float32) / 255.0\n",
    "    inpaint_np = np.array(inpaint_img).astype(np.float32) / 255.0\n",
    "\n",
    "    if gt_np.shape != inpaint_np.shape:\n",
    "        inpaint_img = inpaint_img.resize(gt_img.size, Image.Resampling.LANCZOS)\n",
    "        inpaint_np = np.array(inpaint_img).astype(np.float32) / 255.0\n",
    "\n",
    "    psnr = compute_psnr(gt_np, inpaint_np, data_range=1.0)\n",
    "\n",
    "    min_size = min(gt_np.shape[0], gt_np.shape[1])\n",
    "    win_size = 7 if min_size >= 7 else (min_size if min_size % 2 == 1 else min_size - 1)\n",
    "    ssim = compute_ssim(gt_np, inpaint_np, win_size=win_size, channel_axis=2, data_range=1.0)\n",
    "\n",
    "    gt_tensor = prepare_for_lpips(gt_img)\n",
    "    inpaint_tensor = prepare_for_lpips(inpaint_img)\n",
    "    with torch.no_grad():\n",
    "        lpips_distance = lpips_model(gt_tensor, inpaint_tensor).item()\n",
    "\n",
    "    return psnr, ssim, lpips_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Main combined evaluation\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = \"DUT-OMRON-image\"   # Ground truth images (JPEG)\n",
    "    mask_dir = \"DUT-OMRON-mask\"     # Masks (PNG)\n",
    "    results_dir = \"results\"\n",
    "    lama_dir = os.path.join(results_dir, \"lama\")\n",
    "    controlnet_dir = os.path.join(results_dir, \"controlnet\")\n",
    "    opencv_dir = os.path.join(results_dir, \"opencv\")  # Directory for OpenCV results\n",
    "    os.makedirs(lama_dir, exist_ok=True)\n",
    "    os.makedirs(controlnet_dir, exist_ok=True)\n",
    "    os.makedirs(opencv_dir, exist_ok=True)\n",
    "\n",
    "    pipe = load_controlnet()\n",
    "   \n",
    "    prompt = (\n",
    "        \"Replace the masked region with a natural extension of the surrounding background, ensuring the textures, colors, and lighting blend seamlessly. Do not recreate any specific object shapes from the mask.\"\n",
    "    )\n",
    "\n",
    "    evaluation_results = []\n",
    "    image_paths = sorted(glob(os.path.join(image_dir, \"*.*\")))\n",
    "    pbar = tqdm(image_paths, total=len(image_paths), desc=\"Processing images\", leave=True)\n",
    "    \n",
    "    for image_path in pbar:\n",
    "        filename = os.path.basename(image_path)\n",
    "        basename = os.path.splitext(filename)[0]\n",
    "        mask_path = os.path.join(mask_dir, basename + \".png\")  # Adjust extension if needed\n",
    "        if not os.path.exists(mask_path):\n",
    "            # silently skip missing masks\n",
    "            continue\n",
    "\n",
    "        out_lama = os.path.join(lama_dir, filename)\n",
    "        out_controlnet = os.path.join(controlnet_dir, filename)\n",
    "        out_opencv = os.path.join(opencv_dir, filename)\n",
    "\n",
    "        try:\n",
    "            run_lama_inpaint(image_path, mask_path, out_lama)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Lama for {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            reference_images = None  # or [] if needed\n",
    "            # You can optionally vary the seed per image (e.g., seed = 42 + idx) for diversity\n",
    "            run_controlnet_inpaint(image_path, mask_path, pipe, reference_images, prompt, out_controlnet, seed=42)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in ControlNet for {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            run_opencv_inpaint(image_path, mask_path, out_opencv, refine=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in OpenCV for {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        gt_image = Image.open(image_path).convert(\"RGB\")\n",
    "        lama_result = Image.open(out_lama).convert(\"RGB\")\n",
    "        controlnet_result = Image.open(out_controlnet).convert(\"RGB\")\n",
    "        opencv_result = Image.open(out_opencv).convert(\"RGB\")\n",
    "        \n",
    "        lama_psnr, _, _ = evaluate_metrics(gt_image, lama_result)\n",
    "        controlnet_psnr, _, _ = evaluate_metrics(gt_image, controlnet_result)\n",
    "        opencv_psnr, _, _ = evaluate_metrics(gt_image, opencv_result)\n",
    "        \n",
    "        # Update the progress bar with the latest metrics\n",
    "        pbar.set_postfix({\n",
    "            \"Lama_PSNR\": f\"{lama_psnr:.2f}\",\n",
    "            \"ControlNet_PSNR\": f\"{controlnet_psnr:.2f}\",\n",
    "            \"OpenCV_PSNR\": f\"{opencv_psnr:.2f}\"\n",
    "        })\n",
    "        \n",
    "        evaluation_results.append({\n",
    "            'filename': filename,\n",
    "            'lama_PSNR': lama_psnr,\n",
    "            'controlnet_PSNR': controlnet_psnr,\n",
    "            'opencv_PSNR': opencv_psnr\n",
    "        })\n",
    "        \n",
    "    # Write results to CSV\n",
    "    csv_file_path = \"evaluation_results.csv\"\n",
    "    csv_fields = ['filename', 'lama_PSNR', 'controlnet_PSNR', 'opencv_PSNR']\n",
    "    with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_fields)\n",
    "        writer.writeheader()\n",
    "        for row in evaluation_results:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"Processing images: {len(image_paths)}/{len(image_paths)} completed. Results saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a76827-2ef3-46a0-bd8a-24546147df11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
